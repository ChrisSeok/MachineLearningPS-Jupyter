{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d52c7555552848125b15f77ca87b46d9",
     "grade": false,
     "grade_id": "cell-37fb175d9d3f937f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "This notebook introduces you to Support Vector Machines, it consists of the following three parts:\n",
    "\n",
    "1. <a href=#Part-1:-The-SVM-Problem>The SVM Problem</a>\n",
    "2. <a href=#Part-2:-Kernels>Kernels</a>\n",
    "3. <a href=#(Optional)-Part-3:-$\\nu$-SVM-and-Multiclass-SVM>(Optional) $\\nu$-SVM and Multiclass SVM</a>\n",
    "5. <a href=#(Optional)-Part-4:-Scikit-Learn-Implementation>(Optional) Sckit-Learn Implementation</a>\n",
    "\n",
    "### Programming Tasks\n",
    "For the programming tasks you will need to replace the following comment and exception with your own code:\n",
    "\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "Most programming tasks are followed by a cell with tests (using the `assert` keyword from python). You can consult these cells while developing your implementation and for validation. Note that there may be additional, hidden tests.\n",
    "\n",
    "**<font size=\"3\" color=\"red\">Note</font>**: The `@contract` decorators make sure the data types and shapes are correct for the inputs and outputs. See [here](https://andreacensi.github.io/contracts/tour.html#quick-tour) for more. If you are more comfortable working without these, you can comment out the lines starting with `@contract`. However, in that case it can get tedious to locate the exact source of a bug.\n",
    "\n",
    "### Open Questions\n",
    "The notebook also contains a few open questions. You don't get points for the open questions, they are here to improve your understanding of the topic. For the open questions you can put your answer in the cell below the question, replace the text \"YOUR ANSWER HERE\" with your own answer. You can later check your answer with the answer given in the solution version of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e66ad6bf9c80f65a83495ac9493663b",
     "grade": false,
     "grade_id": "cell-c4c8a039b40d78b9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT INSTALL THE LIBRARIES WHEN WORKING ON ifi-europa.uibk.ac.at\n",
    "\n",
    "# Make sure that the required libraries are installed\n",
    "# If you are using Google Colab, remember to upload the requirements file before \n",
    "# running this cell\n",
    "# If you are running this notebook locally, the requirements file needs to be in \n",
    "# the same location as this notebook\n",
    "import os\n",
    "running_local = True if os.getenv('JUPYTERHUB_USER') is None else False\n",
    "    \n",
    "if running_local:\n",
    "    import sys\n",
    "    !{sys.executable} -m pip install -r requirements_week05.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e7abc87346929b031a6cc1b3097da94",
     "grade": false,
     "grade_id": "cell-cbe97c95cc051344",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "from collections import namedtuple\n",
    "from contracts import contract\n",
    "import numpy as np\n",
    "import cvxopt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.datasets import make_blobs, make_circles, make_moons\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "635ef383eb1bbac18475fa0ab7e67ff1",
     "grade": false,
     "grade_id": "cell-d56011b32dec1274",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Counter for figures\n",
    "figcount = 0\n",
    "\n",
    "# Set the random seed for reproducing results\n",
    "random_seed = 97 \n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Colors to use for plotting\n",
    "colors = [plt.cm.Paired(3), plt.cm.Paired(1), plt.cm.Paired(5)]\n",
    "\n",
    "# Data set namedtuple\n",
    "DataSet = namedtuple(\"DataSet\", (\"X_train\", \"X_test\", \"y_train\", \"y_test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32a849e72114402077035e3c812b3b65",
     "grade": false,
     "grade_id": "cell-d07c53f9db327386",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a href=#Overview> [go to top] </a>\n",
    "# Part 1: The SVM Problem\n",
    "\n",
    "### SVM Optimization Problem\n",
    "Remember from the VO that the SVM optimization problem is defined as follows: \n",
    "\n",
    "$$\n",
    "\\underset{\\mathbf{w}, b}{\\arg \\min} \\frac{1}{2}\\|\\mathbf{w}\\|^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{subject to}\\quad\\quad y_i(\\mathbf{w}^T\\phi\\left(\\mathbf{x}_i) + b\\right) \\geq 1,\\quad i = 1, \\ldots, N\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $\\mathbf{w}$ are the weights of our linear model\n",
    "- $b$ is the bias term of our linear model\n",
    "- $\\mathbf{x}_i$ is the i-th input sample\n",
    "- $y_i$ is i-th target, with a value of $-1$ or $1$\n",
    "\n",
    "### Lagrange Multipliers\n",
    "We can solve the optimization problem above by introducing *lagrange multipliers* $a_i$ for $i = 1, \\ldots, N$ and maximizing the *Lagrangean* $L$:\n",
    "\n",
    "$$L(\\mathbf{w}, b, \\mathbf{a}) = \\frac{1}{2}\\|\\mathbf{w}\\|^2 - \\sum_{i=1}^N a_n\\left[y_i(\\mathbf{w}^T\\phi(\\mathbf{x}_i) + b) - 1\\right]$$\n",
    "\n",
    "We can derive two conditions by taking the derivative w.r.t. $\\mathbf{w}$ and $b$ and setting it to zero:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial \\mathbf{w}} = \\mathbf{w} - \\sum_{i=1}^N a_i y_i\\phi(\\mathbf{x}_i) = 0 \\quad \\longrightarrow \\quad \\mathbf{w} = \\sum_{i=1}^N a_i y_i\\phi(\\mathbf{x}_i)$$\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial b} = -\\sum_{i=1}^N a_i y_i = 0 \\quad \\longrightarrow \\quad \\sum_{i=1}^N a_i y_i = 0$$\n",
    "\n",
    "Substituting both conditions back into $L$ gives us the following *Lagrangean* to maximize:\n",
    "\n",
    "$$\\tilde{L}(\\mathbf{a}) = \\sum_{i=1}^N a_i - \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N a_i a_j y_i y_j \\phi(\\mathbf{x}_i) \\cdot \\phi(\\mathbf{x}_j)$$\n",
    "\n",
    "The optimization problem is:\n",
    "\n",
    "$$\n",
    "\\underset{\\mathbf{a}}{\\arg\\max}\\ \\tilde{L}(\\mathbf{a}) = \\underset{\\mathbf{a}}{\\arg\\max}\\ \\sum_{i=1}^N a_i - \\frac{1}{2} \\sum_{i=1}^N \\sum_{j=1}^N a_i a_j y_i y_j \\phi(\\mathbf{x}_i) \\cdot \\phi(\\mathbf{x}_j) \n",
    "$$\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{subject to}\\quad\\quad\\quad a_i &\\geq 0,\\quad i = 1, \\ldots, N\\\\\n",
    "\\sum_{i=1}^N a_iy_n &= 0\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "### Matrix form\n",
    "We can rewrite the problem above into matrix form. The accompanying [qp_notation_svm.pdf](qp_notation_svm.pdf) shows how to rewrite the formulation given above into matrix form. The optimization problem in matrix form is:\n",
    "\n",
    "$$\\underset{\\mathbf{a}}{\\arg \\max}\\ \\tilde{L}(\\mathbf{a}) = \\underset{\\mathbf{a}}{\\arg\\max}\\ \\mathbb{1}_N^T\\mathbf{a} - \\frac{1}{2}\\mathbf{a}^T\\mathbf{P}\\mathbf{a}$$\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{subject to}\\quad\\quad a_i &\\geq 0, \\quad i=1,\\ldots,N \\\\\n",
    "\\mathbf{y}^T \\mathbf{a} &= 0\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "with \n",
    "\n",
    "- $\\mathbb{1}_N = [1, 1, \\ldots 1]^T \\in \\mathbb{N}^{N}$\n",
    "- $\\mathbf{P} = (\\mathbf{y}\\mathbf{y}^T) \\circ \\mathbf{K}$, where $(\\mathbf{y}\\mathbf{y}^T)$ is the [*outer product*](https://en.wikipedia.org/wiki/Outer_product) and $\\circ$ is the [*Hadamard product*](https://en.wikipedia.org/wiki/Hadamard_product_(matrices)), also known as element wise matrix multiplication.\n",
    "- $\\mathbf{K}$ is the *Gram matrix*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71fe9ab0ef8c2c57daa38978ae9ebaaa",
     "grade": false,
     "grade_id": "cell-acfea57c083db8ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First we are going to look at a binary classification problem in which the data is linearly separable in the input space $\\mathbf{x}$ and where the dataset contains just four points. Most steps for this simple problem can be validated by hand, we highly recommend you do that.\n",
    "\n",
    "The functions in part 1 will be used throughout the notebook.\n",
    "\n",
    "In order to solve the SVM problem we are going to complete the following steps:\n",
    "1. Define the linear kernel and compute the Gram matrix $\\mathbf{K}$\n",
    "2. Compute Matrix $\\mathbf{P}$\n",
    "3. Solve the optmization problem to find $\\mathbf{a}$\n",
    "4. Compute the support vectors\n",
    "5. Compute $\\mathbf{w}$\n",
    "6. Compute $b$\n",
    "7. Define the decision function $f$ and a predictor for $y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9652fd6f63e7ae3dd470eecefac3b73",
     "grade": false,
     "grade_id": "cell-e56ef34da062b07c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_test_data_set():\n",
    "    X_train = np.array([[1, 1],\n",
    "                        [2, 2],\n",
    "                        [3, 3],\n",
    "                        [4, 4]])\n",
    "    \n",
    "    y_train = np.array([-1, -1, 1, 1]) # For SVM we need target values {-1,+1} \n",
    "    X_test = np.array([[1.2, 2.3],\n",
    "                       [2.5, 1.7],\n",
    "                       [2.7, 3.2],\n",
    "                       [3.5, 2.5]])\n",
    "    y_test = np.array([-1, -1, 1, 1])\n",
    "    \n",
    "    return DataSet(X_train, X_test, y_train, y_test)\n",
    "\n",
    "def plot_data(ax, data_set, legend='upper left'):\n",
    "    X_train, X_test, y_train, y_test = data_set\n",
    "    \n",
    "    # Scatter plotting the data, filtering them according the pos/neg values\n",
    "    for y in [-1, 1]:        \n",
    "        ax.scatter(X_train[y_train == y, 0], X_train[y_train == y, 1], \n",
    "                   c=[colors[y]], \n",
    "                   s=30, \n",
    "                   label=r'$y={}$ (train)'.format(y))\n",
    "        ax.scatter(X_test[y_test  == y, 0], X_test[y_test  == y, 1], \n",
    "                   c=[colors[y]], \n",
    "                   s=50, \n",
    "                   marker='x', \n",
    "                   label=r'$y={}$ (test)'.format(y))\n",
    "    \n",
    "    # Set Labels and Limits\n",
    "    ax.set_xlabel(r'$x_0$')\n",
    "    ax.set_ylabel(r'$x_1$')\n",
    "    ax.set_xlim(min(X_train[:, 0].min(), X_test[:,0].min()) - 0.1, \n",
    "                max(X_train[:, 0].max(), X_test[:,0].max()) + 0.1)\n",
    "    ax.set_ylim(min(X_train[:, 1].min(), X_test[:,1].min()) - 0.1, \n",
    "                max(X_train[:, 1].max(), X_test[:,1].max()) + 0.1)\n",
    "    \n",
    "    # Legend\n",
    "    if legend is not None:\n",
    "        pst = ax.legend(loc=legend, frameon=True)\n",
    "        pst.get_frame().set_edgecolor('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e10e83bef3062750620fc6bf98f0a560",
     "grade": false,
     "grade_id": "cell-37ce02bc69658f51",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"385.78125pt\" height=\"262.19625pt\" viewBox=\"0 0 385.78125 262.19625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2022-05-01T11:04:33.298533</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 262.19625 \n",
       "L 385.78125 262.19625 \n",
       "L 385.78125 0 \n",
       "L 0 0 \n",
       "L 0 262.19625 \n",
       "z\n",
       "\" style=\"fill: none\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 43.78125 224.64 \n",
       "L 378.58125 224.64 \n",
       "L 378.58125 7.2 \n",
       "L 43.78125 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"m07ee754cf1\" d=\"M 0 2.738613 \n",
       "C 0.726289 2.738613 1.422928 2.450055 1.936492 1.936492 \n",
       "C 2.450055 1.422928 2.738613 0.726289 2.738613 0 \n",
       "C 2.738613 -0.726289 2.450055 -1.422928 1.936492 -1.936492 \n",
       "C 1.422928 -2.450055 0.726289 -2.738613 0 -2.738613 \n",
       "C -0.726289 -2.738613 -1.422928 -2.450055 -1.936492 -1.936492 \n",
       "C -2.450055 -1.422928 -2.738613 -0.726289 -2.738613 0 \n",
       "C -2.738613 0.726289 -2.450055 1.422928 -1.936492 1.936492 \n",
       "C -1.422928 2.450055 -0.726289 2.738613 0 2.738613 \n",
       "z\n",
       "\" style=\"stroke: #e31a1c\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p275712a738)\">\n",
       "     <use xlink:href=\"#m07ee754cf1\" x=\"54.24375\" y=\"217.845\" style=\"fill: #e31a1c; stroke: #e31a1c\"/>\n",
       "     <use xlink:href=\"#m07ee754cf1\" x=\"158.86875\" y=\"149.895\" style=\"fill: #e31a1c; stroke: #e31a1c\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_2\">\n",
       "    <defs>\n",
       "     <path id=\"m2991d25a33\" d=\"M -3.535534 3.535534 \n",
       "L 3.535534 -3.535534 \n",
       "M -3.535534 -3.535534 \n",
       "L 3.535534 3.535534 \n",
       "\" style=\"stroke: #e31a1c; stroke-width: 1.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p275712a738)\">\n",
       "     <use xlink:href=\"#m2991d25a33\" x=\"75.16875\" y=\"129.51\" style=\"fill: #e31a1c; stroke: #e31a1c; stroke-width: 1.5\"/>\n",
       "     <use xlink:href=\"#m2991d25a33\" x=\"211.18125\" y=\"170.28\" style=\"fill: #e31a1c; stroke: #e31a1c; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_3\">\n",
       "    <defs>\n",
       "     <path id=\"m18f9d320ed\" d=\"M 0 2.738613 \n",
       "C 0.726289 2.738613 1.422928 2.450055 1.936492 1.936492 \n",
       "C 2.450055 1.422928 2.738613 0.726289 2.738613 0 \n",
       "C 2.738613 -0.726289 2.450055 -1.422928 1.936492 -1.936492 \n",
       "C 1.422928 -2.450055 0.726289 -2.738613 0 -2.738613 \n",
       "C -0.726289 -2.738613 -1.422928 -2.450055 -1.936492 -1.936492 \n",
       "C -2.450055 -1.422928 -2.738613 -0.726289 -2.738613 0 \n",
       "C -2.738613 0.726289 -2.450055 1.422928 -1.936492 1.936492 \n",
       "C -1.422928 2.450055 -0.726289 2.738613 0 2.738613 \n",
       "z\n",
       "\" style=\"stroke: #1f78b4\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p275712a738)\">\n",
       "     <use xlink:href=\"#m18f9d320ed\" x=\"263.49375\" y=\"81.945\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n",
       "     <use xlink:href=\"#m18f9d320ed\" x=\"368.11875\" y=\"13.995\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_4\">\n",
       "    <defs>\n",
       "     <path id=\"mfcfc9c59b9\" d=\"M -3.535534 3.535534 \n",
       "L 3.535534 -3.535534 \n",
       "M -3.535534 -3.535534 \n",
       "L 3.535534 3.535534 \n",
       "\" style=\"stroke: #1f78b4; stroke-width: 1.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p275712a738)\">\n",
       "     <use xlink:href=\"#mfcfc9c59b9\" x=\"232.10625\" y=\"68.355\" style=\"fill: #1f78b4; stroke: #1f78b4; stroke-width: 1.5\"/>\n",
       "     <use xlink:href=\"#mfcfc9c59b9\" x=\"315.80625\" y=\"115.92\" style=\"fill: #1f78b4; stroke: #1f78b4; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m8ba055f832\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8ba055f832\" x=\"54.24375\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(46.292187 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8ba055f832\" x=\"106.55625\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 1.5 -->\n",
       "      <g transform=\"translate(98.604688 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8ba055f832\" x=\"158.86875\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 2.0 -->\n",
       "      <g transform=\"translate(150.917188 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8ba055f832\" x=\"211.18125\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2.5 -->\n",
       "      <g transform=\"translate(203.229688 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8ba055f832\" x=\"263.49375\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 3.0 -->\n",
       "      <g transform=\"translate(255.542187 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8ba055f832\" x=\"315.80625\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 3.5 -->\n",
       "      <g transform=\"translate(307.854687 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m8ba055f832\" x=\"368.11875\" y=\"224.64\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 4.0 -->\n",
       "      <g transform=\"translate(360.167187 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_8\">\n",
       "     <!-- $x_0$ -->\n",
       "     <g transform=\"translate(205.83125 252.916562)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-Oblique-78\" d=\"M 3841 3500 \n",
       "L 2234 1784 \n",
       "L 3219 0 \n",
       "L 2559 0 \n",
       "L 1819 1388 \n",
       "L 531 0 \n",
       "L -166 0 \n",
       "L 1556 1844 \n",
       "L 641 3500 \n",
       "L 1300 3500 \n",
       "L 1972 2234 \n",
       "L 3144 3500 \n",
       "L 3841 3500 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.3125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-30\" transform=\"translate(59.179688 -16.09375)scale(0.7)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <defs>\n",
       "       <path id=\"m82785320cb\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m82785320cb\" x=\"43.78125\" y=\"217.845\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(20.878125 221.644219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m82785320cb\" x=\"43.78125\" y=\"183.87\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1.5 -->\n",
       "      <g transform=\"translate(20.878125 187.669219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m82785320cb\" x=\"43.78125\" y=\"149.895\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 2.0 -->\n",
       "      <g transform=\"translate(20.878125 153.694219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m82785320cb\" x=\"43.78125\" y=\"115.92\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 2.5 -->\n",
       "      <g transform=\"translate(20.878125 119.719219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m82785320cb\" x=\"43.78125\" y=\"81.945\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 3.0 -->\n",
       "      <g transform=\"translate(20.878125 85.744219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m82785320cb\" x=\"43.78125\" y=\"47.97\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 3.5 -->\n",
       "      <g transform=\"translate(20.878125 51.769219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m82785320cb\" x=\"43.78125\" y=\"13.995\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 4.0 -->\n",
       "      <g transform=\"translate(20.878125 17.794219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_16\">\n",
       "     <!-- $x_1$ -->\n",
       "     <g transform=\"translate(14.798438 121.27)rotate(-90)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-78\" transform=\"translate(0 0.3125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(59.179688 -16.09375)scale(0.7)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 43.78125 224.64 \n",
       "L 43.78125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 378.58125 224.64 \n",
       "L 378.58125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 43.78125 224.64 \n",
       "L 378.58125 224.64 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 43.78125 7.2 \n",
       "L 378.58125 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 50.78125 74 \n",
       "L 153.88125 74 \n",
       "Q 155.88125 74 155.88125 72 \n",
       "L 155.88125 14.2 \n",
       "Q 155.88125 12.2 153.88125 12.2 \n",
       "L 50.78125 12.2 \n",
       "Q 48.78125 12.2 48.78125 14.2 \n",
       "L 48.78125 72 \n",
       "Q 48.78125 74 50.78125 74 \n",
       "z\n",
       "\" style=\"fill: #ffffff; opacity: 0.8; stroke: #000000; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"PathCollection_5\">\n",
       "     <g>\n",
       "      <use xlink:href=\"#m07ee754cf1\" x=\"62.78125\" y=\"21.175\" style=\"fill: #e31a1c; stroke: #e31a1c\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- $y=-1$ (train) -->\n",
       "     <g transform=\"translate(80.78125 23.8)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-Oblique-79\" d=\"M 1588 -325 \n",
       "Q 1188 -997 936 -1164 \n",
       "Q 684 -1331 294 -1331 \n",
       "L -159 -1331 \n",
       "L -63 -850 \n",
       "L 269 -850 \n",
       "Q 509 -850 678 -719 \n",
       "Q 847 -588 1056 -206 \n",
       "L 1234 128 \n",
       "L 459 3500 \n",
       "L 1069 3500 \n",
       "L 1650 819 \n",
       "L 3256 3500 \n",
       "L 3859 3500 \n",
       "L 1588 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \n",
       "L 4684 2906 \n",
       "L 4684 2381 \n",
       "L 678 2381 \n",
       "L 678 2906 \n",
       "z\n",
       "M 678 1631 \n",
       "L 4684 1631 \n",
       "L 4684 1100 \n",
       "L 678 1100 \n",
       "L 678 1631 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \n",
       "Q 1566 4138 1362 3434 \n",
       "Q 1159 2731 1159 2009 \n",
       "Q 1159 1288 1364 580 \n",
       "Q 1569 -128 1984 -844 \n",
       "L 1484 -844 \n",
       "Q 1016 -109 783 600 \n",
       "Q 550 1309 550 2009 \n",
       "Q 550 2706 781 3412 \n",
       "Q 1013 4119 1484 4856 \n",
       "L 1984 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \n",
       "L 1013 4856 \n",
       "Q 1481 4119 1714 3412 \n",
       "Q 1947 2706 1947 2009 \n",
       "Q 1947 1309 1714 600 \n",
       "Q 1481 -109 1013 -844 \n",
       "L 513 -844 \n",
       "Q 928 -128 1133 580 \n",
       "Q 1338 1288 1338 2009 \n",
       "Q 1338 2731 1133 3434 \n",
       "Q 928 4138 513 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-79\" transform=\"translate(0 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-3d\" transform=\"translate(78.662109 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(201.416016 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(304.6875 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(368.310547 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(400.097656 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(439.111328 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(478.320312 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(519.433594 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(580.712891 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(608.496094 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(671.875 0.015625)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"PathCollection_6\">\n",
       "     <g>\n",
       "      <use xlink:href=\"#m2991d25a33\" x=\"62.78125\" y=\"35.875\" style=\"fill: #e31a1c; stroke: #e31a1c; stroke-width: 1.5\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- $y=-1$ (test) -->\n",
       "     <g transform=\"translate(80.78125 38.5)scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-79\" transform=\"translate(0 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-3d\" transform=\"translate(78.662109 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2212\" transform=\"translate(201.416016 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(304.6875 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(368.310547 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(400.097656 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(439.111328 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(478.320312 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(539.84375 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(591.943359 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(631.152344 0.125)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"PathCollection_7\">\n",
       "     <g>\n",
       "      <use xlink:href=\"#m18f9d320ed\" x=\"62.78125\" y=\"50.575\" style=\"fill: #1f78b4; stroke: #1f78b4\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_19\">\n",
       "     <!-- $y=1$ (train) -->\n",
       "     <g transform=\"translate(80.78125 53.2)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-79\" transform=\"translate(0 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-3d\" transform=\"translate(78.662109 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(181.933594 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(245.556641 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(277.34375 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(316.357422 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" transform=\"translate(355.566406 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-61\" transform=\"translate(396.679688 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" transform=\"translate(457.958984 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" transform=\"translate(485.742188 0.015625)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(549.121094 0.015625)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"PathCollection_8\">\n",
       "     <g>\n",
       "      <use xlink:href=\"#mfcfc9c59b9\" x=\"62.78125\" y=\"65.275\" style=\"fill: #1f78b4; stroke: #1f78b4; stroke-width: 1.5\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_20\">\n",
       "     <!-- $y=1$ (test) -->\n",
       "     <g transform=\"translate(80.78125 67.9)scale(0.1 -0.1)\">\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-79\" transform=\"translate(0 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-3d\" transform=\"translate(78.662109 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-31\" transform=\"translate(181.933594 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-20\" transform=\"translate(245.556641 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(277.34375 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(316.357422 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" transform=\"translate(355.566406 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" transform=\"translate(417.089844 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" transform=\"translate(469.189453 0.125)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(508.398438 0.125)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p275712a738\">\n",
       "   <rect x=\"43.78125\" y=\"7.2\" width=\"334.8\" height=\"217.44\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get data set\n",
    "test_data_set = get_test_data_set()\n",
    "\n",
    "# Plot data\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "plot_data(ax, test_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b638b2344ac3613d0db77e0f436d187",
     "grade": false,
     "grade_id": "cell-a52115e4d69cdb0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Linear Kernel\n",
    "It is clear that the data is linearly separable in the input space $\\mathbf{x}$. Therefore we do not need to transform our data using some feature mapping, i.e., we can use the linear feature $\\phi(\\mathbf{x}) = \\mathbf{x}$. The *linear kernel* is the kernel associated with $\\phi(\\mathbf{x}) = \\mathbf{x}$. The first task is to derive the linear kernel and write a function that computes it.\n",
    "\n",
    "Later on we will need to calculate the kernel between two sets of datapoints, e.g., the Gram matrix. Write the `linear_kernel` function below in such a way it can compute the kernel between two vectors and between two matrices:\n",
    "\n",
    "- For two data points $\\mathbf{x}_1 = [1, 1, 1]$ and $\\mathbf{x}_2 = [2, 2, 2]$ the kernel is \n",
    "$$k(\\mathbf{x}_1, \\mathbf{x}_2) = \\phi(\\mathbf{x}_1)^T\\phi(\\mathbf{x}_2)$$\n",
    "- For two data sets $\\mathbf{X}_1 = [\\mathbf{x}_{11}, \\mathbf{x}_{12}, \\mathbf{x}_{13}]^T$ and $\\mathbf{X}_2 = [\\mathbf{x}_{21}, \\mathbf{x}_{22}]^T$ the kernel is \n",
    "$$k(\\mathbf{X}_1, \\mathbf{X}_2) = \\left[\\begin{array}{cc}\n",
    "    k(\\mathbf{x}_{11}, \\mathbf{x}_{12}) & k(\\mathbf{x}_{11}, \\mathbf{x}_{22}) \\\\\n",
    "    k(\\mathbf{x}_{12}, \\mathbf{x}_{12}) & k(\\mathbf{x}_{12}, \\mathbf{x}_{22}) \\\\\n",
    "    k(\\mathbf{x}_{13}, \\mathbf{x}_{12}) & k(\\mathbf{x}_{13}, \\mathbf{x}_{22}) \\\\\n",
    "\\end{array}\\right]$$ \n",
    "\n",
    "Note that the two matrices do not need to contain the same number of datapoints, but the datapoints do need to be of the same dimension. Furthermore note that $k(\\mathbf{X}_1, \\mathbf{X}_1)$ is the Gram matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb3a2e73de323826b862824992db299b",
     "grade": false,
     "grade_id": "cell-c85818ef313e377d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(x_i='array[M] | array[NxM]',\n",
    "          x_j='array[M] | array[KxM]',\n",
    "          returns='number | array[NxK] ')\n",
    "def linear_kernel(x_i, x_j):\n",
    "    \"\"\"\n",
    "    Compute the linear kernel between two arrays of data.\n",
    "    \n",
    "    NOTE: x_i and x_j can be both one-dimensional arrays or \n",
    "          both two-dimensional arrays.\n",
    "         \n",
    "    TIP: Try to avoid using any loops, use numpy methods instead.\n",
    "    \n",
    "    :param x_i: first input array\n",
    "    :param x_j: second input array\n",
    "    :returns:   linear kernel\n",
    "    \"\"\"\n",
    "    assert x_i.ndim == x_j.ndim, f\"Kernel only accepts two inputs with the same number of dimensions.\\n\\\n",
    "    \\t x_i.ndim = {x_i.ndim}\\n\\\n",
    "    \\t x_j.ndim = {x_j.ndim}\"\n",
    "    \n",
    "  \n",
    "    k = x_i@ np.transpose(x_j)\n",
    "\n",
    "    \n",
    "    return k\n",
    "\n",
    "@contract(x='array[M] | array[NxM]',\n",
    "          returns='array[M] | array[NxM]')\n",
    "def linear_feature(x):\n",
    "    \"\"\"\n",
    "    Returns the feature associated with the linear kernel:\n",
    "    \n",
    "      phi(x) = x\n",
    "    \n",
    "    :param x: input array\n",
    "    :returns: feature\n",
    "    \"\"\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e06daa2529b20c5c235f986f40052156",
     "grade": true,
     "grade_id": "cell-2598323f30284e8c-part-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:\n",
      "[[ 2  4  6  8]\n",
      " [ 4  8 12 16]\n",
      " [ 6 12 18 24]\n",
      " [ 8 16 24 32]]\n"
     ]
    }
   ],
   "source": [
    "# Test with vectors\n",
    "x_i = np.array([1, 2, 3])\n",
    "x_j = np.array([1, 1, 1])\n",
    "\n",
    "assert linear_kernel(x_i, x_i) == 14\n",
    "assert linear_kernel(x_i, x_j) == 6\n",
    "assert linear_kernel(x_j, x_j) == 3\n",
    "\n",
    "# Test with matrices\n",
    "X_i = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "X_j = np.array([[1, 2, 3], [2, 3, 4]])\n",
    "\n",
    "assert np.allclose(linear_kernel(X_i, X_j), np.array([[6, 9], [12, 18], [18, 27]]))\n",
    "assert np.allclose(linear_kernel(X_i, X_i), np.array([[3, 6, 9], [6, 12, 18], [9, 18, 27]]))\n",
    "\n",
    "# Test Gram matrix on test_data_set\n",
    "K_true = np.asarray([[2,  4,  6,  8],\n",
    "                     [4,  8, 12, 16],\n",
    "                     [6, 12, 18, 24],\n",
    "                     [8, 16, 24, 32]])\n",
    "\n",
    "K = linear_kernel(test_data_set.X_train, test_data_set.X_train)\n",
    "print(\"K:\")\n",
    "print(K)\n",
    "\n",
    "assert np.allclose(K, K_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89756151032d3a5d3471a57407024e73",
     "grade": false,
     "grade_id": "cell-6f6a9634d36ab0a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Matrix P\n",
    "Now that we have our kernel and Gram matrix we can start defining the other variables for our optimization problem. One of the variables we need is the matrix $\\mathbf{P} = (\\mathbf{y}\\mathbf{y}^T) \\circ \\mathbf{K}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45429c15b57bad1c453731d64e008feb",
     "grade": false,
     "grade_id": "cell-4cabb15a5d28e752",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(K='array[NxN]',\n",
    "          y='array[N]',\n",
    "          returns='array[NxN]')\n",
    "def compute_P(K, y):\n",
    "    \"\"\"\n",
    "    Compute matrix P.\n",
    "    \n",
    "    :param K: Gram matrix\n",
    "    :param y: target values\n",
    "    :returns: matrix P\n",
    "    \"\"\"\n",
    "\n",
    "    # use np functions\n",
    "    yy = np.outer(y,np.transpose(y))\n",
    "    P = np.multiply(yy,K) #hadamard product\n",
    "    \n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d5bac64fbd7f28e69b01d3118781d7be",
     "grade": true,
     "grade_id": "cell-8672c5f57e1ac374-part-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:\n",
      "[[  2   4  -6  -8]\n",
      " [  4   8 -12 -16]\n",
      " [ -6 -12  18  24]\n",
      " [ -8 -16  24  32]]\n"
     ]
    }
   ],
   "source": [
    "P_true = np.asarray([[ 2,   4,  -6,  -8],\n",
    "                     [ 4,   8, -12, -16],\n",
    "                     [-6, -12,  18,  24],\n",
    "                     [-8, -16,  24,  32]])\n",
    "\n",
    "P = compute_P(K, test_data_set.y_train)\n",
    "print(\"P:\")\n",
    "print(P)\n",
    "\n",
    "assert np.allclose(P, P_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b483812f4e92a29d8be018f52929bade",
     "grade": false,
     "grade_id": "cell-126ea2f38f1b24ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Solving the Optimization\n",
    "Now it is time to solve the SVM optimization problem using the functions you have defined above. Remember that the optimization problem is:\n",
    "\n",
    "$$\\underset{\\mathbf{a}}{\\text{maximize}}\\ \\mathbb{1}_N^T\\mathbf{a} - \\frac{1}{2}\\mathbf{a}^T\\mathbf{P}\\mathbf{a}$$\n",
    "$$\n",
    "\\begin{split}\n",
    "\\text{subject to}\\quad\\quad a_i &\\geq 0, \\quad i=1,\\ldots,N \\\\\n",
    "\\mathbf{y}^T \\mathbf{a} &= 0\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "We don't want you to be spending too much time on having to figure out the `cvxopt` library, therefore the `optimize_svm` function is given. Go through the code to validate for yourself what is happening and what each function means. Also have a look at the [cvxopt](https://cvxopt.org) documentation or use the build in documentation viewer (e.g., `cvxopt.solvers.qp?`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "995e755f35069c674a17c3997dc21da1",
     "grade": false,
     "grade_id": "cell-1ace34f8625bc9c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(X='array[NxM]',\n",
    "          y='array[N]',\n",
    "          returns='array[N]')\n",
    "def optimize_svm(X, y, kernel=linear_kernel):\n",
    "    \"\"\"\n",
    "    Solves the the quadratic programming problem.\n",
    "    \n",
    "    The optimization does not always succeed, this can\n",
    "    have several causes. \n",
    "    \n",
    "    When you get the error that the problem is not DCP \n",
    "    we recommend trying different hyperparameters or a \n",
    "    different kernel. Often the reason for this problem\n",
    "    is that the data is not linearly separable in the \n",
    "    feature space.\n",
    "    \n",
    "    Another error that can occur is that the solver\n",
    "    was not able to find a solution. In this case, run\n",
    "    the optimization again. Sometimes it was just some\n",
    "    initialization error within the solver. If the solver\n",
    "    keeps failing to solve the problem you have to change\n",
    "    the hyperparameters or kernel.\n",
    "    \n",
    "    The main reason for problems however is wrongly \n",
    "    implemented methods. So step one should always be,\n",
    "    check your implementation.\n",
    "    \n",
    "    :param X:      training values\n",
    "    :param y:      target values\n",
    "    :param kernel: kernel function (function or callable object)\n",
    "    :returns:      Lagrangian multipliers\n",
    "                   None if optimization fails\n",
    "    \"\"\"\n",
    "    N = y.shape[0]\n",
    "    \n",
    "    K = kernel(X, X)\n",
    "    P = compute_P(K, y)\n",
    "    P = 0.5 * (P + P.T) # make sure P is symmetric, increases stability of optimization\n",
    "    \n",
    "    K = cvxopt.matrix(K)\n",
    "    P = cvxopt.matrix(P)\n",
    "    q = cvxopt.matrix(-1.0 * np.ones(N))\n",
    "    \n",
    "    # Equality constraints\n",
    "    A = cvxopt.matrix(y.astype('float'), (1, N))\n",
    "    b = cvxopt.matrix(0.0)\n",
    "    \n",
    "    # Inequality constraints\n",
    "    G = cvxopt.matrix(np.diag(-1.0 * np.ones(N)))\n",
    "    h = cvxopt.matrix(np.zeros(N).astype('float'))\n",
    "        \n",
    "    # Solve the quadratic programming problem\n",
    "    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    \n",
    "    if 'optimal' not in solution['status']:\n",
    "        print(\"No solution could be found, is the data linearly separable in the feature space?\")\n",
    "        return None\n",
    "    \n",
    "    # Lagrangian multipliers\n",
    "    return np.ravel(solution['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7b756e6bb764a03015ccfd3521d06c2",
     "grade": true,
     "grade_id": "cell-9af554f4a6a68967-part-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.5868e-01 -1.9174e+00  7e+00  2e+00  2e+00\n",
      " 1: -1.4398e+00 -1.5363e+00  7e-01  2e-01  2e-01\n",
      " 2: -9.9503e-01 -1.0507e+00  6e-02  3e-16  4e-15\n",
      " 3: -9.9995e-01 -1.0005e+00  5e-04  3e-16  2e-15\n",
      " 4: -1.0000e+00 -1.0000e+00  5e-06  5e-17  2e-15\n",
      " 5: -1.0000e+00 -1.0000e+00  5e-08  3e-16  2e-15\n",
      "Optimal solution found.\n",
      "\n",
      "a: [1.21694401e-09 1.00000002e+00 1.00000002e+00 1.21694401e-09]\n"
     ]
    }
   ],
   "source": [
    "a = optimize_svm(test_data_set.X_train, test_data_set.y_train, linear_kernel)\n",
    "print(\"\\na:\", a)\n",
    "\n",
    "assert np.allclose(a, [0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3e644aa56d063b7af99d289dd94778f",
     "grade": false,
     "grade_id": "cell-230945c40385cfd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Computing the Support Vectors\n",
    "\n",
    "##### Note on Numerical Values:\n",
    "Since we are working with numerical optimization, results\n",
    "will have small errors and cannot be compared directly. We \n",
    "can work around this problem by using small thresholds. \n",
    "\n",
    "For example:\n",
    "We have a true value `y = 0` and some numerical optimization \n",
    "calculates an estimate `yhat = 0.0000001` for `y`. Comparing \n",
    "using `y == yhat` gives back `False`. Instead we can use\n",
    "`yhat < threshold` to circumvent the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c41d9641fa64766e8c614f0712443613",
     "grade": false,
     "grade_id": "cell-ce6252c4682b6171",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(a='array[N]',\n",
    "          threshold='float',\n",
    "          returns='array[S]')\n",
    "def compute_svi(a, threshold=1e-5):\n",
    "    \"\"\"\n",
    "    Compute the indices of the support vectors.\n",
    "    \n",
    "    TIP: Remember that support vectors correspond to \n",
    "         indices that have a lagrange multiplier > 0.\n",
    "         \n",
    "    TIP: Try to avoid using any loops, use numpy methods instead.\n",
    "    \n",
    "    :param a:         Lagrange multipliers\n",
    "    :param threshold: threshold value\n",
    "    :returns:         indices of the support vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    svi = a+threshold\n",
    "    \n",
    "    return svi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d589dfbf58349655729352c831cc1b3",
     "grade": true,
     "grade_id": "cell-d4b2aaa07f178ef5-part-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.5868e-01 -1.9174e+00  7e+00  2e+00  2e+00\n",
      " 1: -1.4398e+00 -1.5363e+00  7e-01  2e-01  2e-01\n",
      " 2: -9.9503e-01 -1.0507e+00  6e-02  3e-16  4e-15\n",
      " 3: -9.9995e-01 -1.0005e+00  5e-04  3e-16  2e-15\n",
      " 4: -1.0000e+00 -1.0000e+00  5e-06  5e-17  2e-15\n",
      " 5: -1.0000e+00 -1.0000e+00  5e-08  3e-16  2e-15\n",
      "Optimal solution found.\n",
      "a: [1.21694401e-09 1.00000002e+00 1.00000002e+00 1.21694401e-09]\n",
      "\n",
      "svi: [1.00012169e-05 1.00001002e+00 1.00001002e+00 1.00012169e-05]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_195/114239027.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nsvi:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msupport_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msvi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"support vectors:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "a = optimize_svm(test_data_set.X_train, test_data_set.y_train, linear_kernel)\n",
    "print(\"a:\", a)\n",
    "\n",
    "svi = compute_svi(a)\n",
    "print(\"\\nsvi:\", svi)\n",
    "\n",
    "support_vectors = test_data_set.X_train[svi]\n",
    "print(\"support vectors:\")\n",
    "print(support_vectors)\n",
    "\n",
    "assert np.allclose(svi, [1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "24a9e29423bc9094f9830421ba514942",
     "grade": false,
     "grade_id": "cell-635fee4ce5cca4ef",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1: what do support vectors represent?\n",
    "The SVM tries to find a decision boundary that separates two classes with the widest margin. For points on the decision boundary we know that the decision function equals zero:\n",
    "\n",
    "$$f(\\mathbf{x}) = \\mathbf{w}^T\\phi(\\mathbf{x}) + b = 0$$\n",
    "\n",
    "What is the value of the decision function for the support vectors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "762908526b791b98033d8db561fcf131",
     "grade": true,
     "grade_id": "cell-dcaae8b35d07a5f5-part-1",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21610ff12375279ef95e825b6f0d8cc6",
     "grade": false,
     "grade_id": "cell-09a20df6364bb1e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Computing $\\mathbf{w}$ \n",
    "\n",
    "We can compute $\\mathbf{w}$ using the following equation:\n",
    "\n",
    "$$\\mathbf{w} = \\sum_{i=1}^N a_i y_i\\phi(\\mathbf{x}_i)$$\n",
    "\n",
    "\n",
    "Note: for the computation of $\\mathbf{w}$ we require the feature mapping $\\phi$. But we do not actually need the feature mapping $\\phi$ for solving the SVM problem, i.e., we don't need to compute the actual values for $\\mathbf{w}$ to solve the SVM problem. This will become clear later on in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0fa847b00863dd18456a9ebe2bed66b",
     "grade": false,
     "grade_id": "cell-e1e6cc3a2df3c1a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(a='array[N]',\n",
    "          y='array[N]',\n",
    "          X='array[NxM]',\n",
    "          returns='array[M]')\n",
    "def compute_w(a, y, X, feature=linear_feature):\n",
    "    \"\"\"\n",
    "    Compute weight vector w for the linear kernel\n",
    "    \n",
    "    TIP: Try to avoid using any loops, use numpy methods instead.\n",
    "    \n",
    "    :param a:       Lagrange multipliers\n",
    "    :param y:       target values\n",
    "    :param x:       training vectors\n",
    "    :param feature: feature mapping (function or callable object)\n",
    "    :returns:       weights\n",
    "    \"\"\"\n",
    "    \n",
    "    w = a*y@X\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c76ea14a8aa84b3f274963db74cff27f",
     "grade": true,
     "grade_id": "cell-5380efb8979b2d59-part-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -9.5868e-01 -1.9174e+00  7e+00  2e+00  2e+00\n",
      " 1: -1.4398e+00 -1.5363e+00  7e-01  2e-01  2e-01\n",
      " 2: -9.9503e-01 -1.0507e+00  6e-02  3e-16  4e-15\n",
      " 3: -9.9995e-01 -1.0005e+00  5e-04  3e-16  2e-15\n",
      " 4: -1.0000e+00 -1.0000e+00  5e-06  5e-17  2e-15\n",
      " 5: -1.0000e+00 -1.0000e+00  5e-08  3e-16  2e-15\n",
      "Optimal solution found.\n",
      "a: [1.21694401e-09 1.00000002e+00 1.00000002e+00 1.21694401e-09]\n",
      "\n",
      "w: [1.00000003 1.00000003]\n"
     ]
    }
   ],
   "source": [
    "a = optimize_svm(test_data_set.X_train, test_data_set.y_train, linear_kernel)\n",
    "print(\"a:\", a)\n",
    "\n",
    "w = compute_w(a, test_data_set.y_train, test_data_set.X_train)\n",
    "print(\"\\nw:\", w)\n",
    "\n",
    "assert np.allclose(w, [1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85f759feb306be29127bec1ba8291f64",
     "grade": false,
     "grade_id": "cell-b3a39d9c71c15faa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Computing $b$\n",
    "The decision function is defined as:\n",
    "\n",
    "$$f(\\mathbf{x}) = \\mathbf{w}^T\\phi(\\mathbf{x}) + b$$\n",
    "\n",
    "for the support vectors $\\mathbf{x}_s \\in \\mathcal{S}$, where $\\mathcal{S}$ denotes the set of all support vectors, we know that: \n",
    "\n",
    "$$f(\\mathbf{x_s}) = \\mathbf{w}^T\\phi(\\mathbf{x_s}) + b = y_s$$ \n",
    "\n",
    "the values for $\\mathbf{w}$ and $\\mathbf{x}_s$ are known, so we can solve for $b$:\n",
    "\n",
    "$$b = y_s - \\mathbf{w}^T\\phi(\\mathbf{x_s})$$\n",
    "\n",
    "But which support vector $\\mathbf{x}_s$ do we use? It turns out that just using one value might result in stability issues. A commonly used solution is to average over all support vectors $\\mathcal{S}$:\n",
    "\n",
    "$$b = \\frac{1}{|\\mathcal{S}|}\\sum_{i \\in \\mathcal{S}}y_i - \\mathbf{w}^T\\phi(\\mathbf{x}_i)$$\n",
    "\n",
    "One more issue remains, our expression for $b$ contains the feature $\\phi(\\mathbf{x}_i)$. One nice property of SVMs is that the feature mapping $\\phi$ does not have to be known, but only a kernel $k(\\mathbf{x}_i, \\mathbf{x}_j)$ that is valid for $\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d2a93bc2e1c50ce7c25275dbc6d3588",
     "grade": false,
     "grade_id": "cell-91f4773f600c3ce4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2: What is an advantage of using $k$ instead of $\\phi$?\n",
    "Remember that a kernel function is defined as $k(\\mathbf{x}_i, \\mathbf{x}_j) = \\phi(\\mathbf{x}_i)^T\\phi(\\mathbf{x}_j)$. Tip: how does the feature mapping $\\phi$ of, for example, $k(\\mathbf{x}_i, \\mathbf{x}_j) = (\\mathbf{x}_i^T\\mathbf{x}_j)^2$ look?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b373bba469a4de650f5fb001c13d05e",
     "grade": true,
     "grade_id": "cell-045cc4cd7fbef940",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f6351d44231d8f8c7635d58aaf53dff",
     "grade": false,
     "grade_id": "cell-981595484b3b2723",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Rewrite the expression for $b$ into a form that uses the kernel function $k(\\mathbf{x}_i, \\mathbf{x}_j)$ instead of $\\phi(\\mathbf{x}_i)$. Substitute the expression for $\\mathbf{w}$ into the equation for $b$. Use the rewritten expression in the tasks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35b6f3e578c8bbe947e0da4e2f55c964",
     "grade": false,
     "grade_id": "cell-8a0764aab7e7b999",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(a_sv='array[S]',\n",
    "          y_sv='array[S]',\n",
    "          support_vectors='array[SxM]',\n",
    "          returns='number')\n",
    "def compute_b(a_sv, y_sv, support_vectors, kernel=linear_kernel):\n",
    "    \"\"\"\n",
    "    Compute the bias variable `b` using the averaging approach.\n",
    "    \n",
    "    TIP: Try to avoid using any loops, use numpy methods instead.\n",
    "    \n",
    "    :param a_sv:            lagrange multipliers corresponding to the support vectors \n",
    "    :param y_sv:            target values corresponding to the support vectors\n",
    "    :param support_vectors: support vectors\n",
    "    :param kernel:          kernel\n",
    "    :returns:               bias variable\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "    raise NotImplementedError()\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "639163cbc4c26dc08b1332366ecc45dc",
     "grade": false,
     "grade_id": "cell-0329434305944090",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For a linear kernel the feature mapping is particularly easy: $\\phi(\\mathbf{x}) = \\mathbf{x}$. We will use this for evaluating the function `compute_b` by comparing the results with the expression:\n",
    "\n",
    "$$b = \\frac{1}{|\\mathcal{S}|}\\sum_{i \\in \\mathcal{S}}y_i - \\mathbf{w}^T\\phi(\\mathbf{x}_i)$$\n",
    "\n",
    "Solve this exercise by hand an add the solution in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f9f7a1d1b7b272024274414a5ae6146",
     "grade": false,
     "grade_id": "cell-c34339e046e9fd2c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(returns='number')\n",
    "def b_features():\n",
    "    \"\"\"\n",
    "    Return the value you found by solving the equation above.\n",
    "    \n",
    "    Compute the value for b by hand and assign it to variable b:\n",
    "    \n",
    "        b = REPLACE_WITH_YOUR_VALUE_FOR_B\n",
    "    \n",
    "    :returns: bias b\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d4330fcd30c04dbb0c0e1d2f592e8ad",
     "grade": true,
     "grade_id": "cell-47532b4820466b3e-part-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "a = optimize_svm(test_data_set.X_train, test_data_set.y_train, linear_kernel)\n",
    "print(\"a:\", a)\n",
    "\n",
    "svi = compute_svi(a)\n",
    "print(\"svi:\", svi)\n",
    "\n",
    "# Support vectors\n",
    "support_vectors = test_data_set.X_train[svi]\n",
    "a_sv = a[svi]\n",
    "y_sv = test_data_set.y_train[svi]\n",
    "\n",
    "# Disable linear_feature function for testing\n",
    "_linear_feature = linear_feature\n",
    "try:\n",
    "    def linear_feature(x):\n",
    "        raise AssertionError(\"Your `compute_b` function uses the `linear_feature` function which is not allowed.\")\n",
    "        \n",
    "    b = compute_b(a_sv, y_sv, support_vectors, linear_kernel)\n",
    "except AssertionError as e:\n",
    "    raise e\n",
    "finally:\n",
    "    linear_feature = _linear_feature\n",
    "    \n",
    "# Print result and test\n",
    "print(\"\\nb:\", b)\n",
    "assert abs(b - b_features()) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20805d4152c5c921b839a2aa68f74ad6",
     "grade": false,
     "grade_id": "cell-e1f17d0bb7359119",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Decision Function and Prediction \n",
    "We now have all the components for our model, the next step is to use them for making predictions. We split the prediction into two parts, first part is the decision function $f$. The predictor can use the decision function for making predictions. We will also define an accuracy metric for evaluating the accuracy of our model on a test set.\n",
    "\n",
    "Your implementation for the `decision_function` and `predict` should use the kernel function $k(\\mathbf{x}_i, \\mathbf{x}_j)$ and not $\\phi(\\mathbf{x}_i)$. Substitute the expression for $\\mathbf{w}$ into the decision function $f(\\mathbf{x})$ and rewrite such that $\\phi$ disappears (like you did for the expression for $b$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48ce4217cbd8a72f638f3677d7834521",
     "grade": false,
     "grade_id": "cell-8cd66669619f5530",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(X_pred='array[KxM]',\n",
    "          a='array[N]',\n",
    "          y_train='array[N]',\n",
    "          X_train='array[NxM]',\n",
    "          b='number',\n",
    "          returns='array[K]')\n",
    "def decision_function(X_pred, a, y_train, X_train, b, kernel=linear_kernel):\n",
    "    \"\"\"\n",
    "    The decision function tells us on which side of the decision boundary \n",
    "    generated by `f` a set of samples `X_pred` is located\n",
    "    \n",
    "    TIP: Try to avoid using any loops, use numpy methods instead.\n",
    "    \n",
    "    :param X_pred:  input samples to predict the decision function for\n",
    "    :param a:       lagrange multipliers\n",
    "    :param y_train: target samples from the training set \n",
    "    :param X_train: input samples from the training set\n",
    "    :param b:       bias variable\n",
    "    :param kernel:  kernel (function or callable object)\n",
    "    :returns:       decision function value\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return f\n",
    "    \n",
    "@contract(X_pred='array[KxM]',\n",
    "          a='array[N]',\n",
    "          y_train='array[N]',\n",
    "          X_train='array[NxM]',\n",
    "          b='number',\n",
    "          returns='array[K]')   \n",
    "def predict(X_pred, a, y_train, X_train, b, kernel=linear_kernel):\n",
    "    \"\"\"\n",
    "    Predicts the target value for a set of samples `X_pred`\n",
    "    \n",
    "    For each sample `x` in `X_pred` the target value must be `y=1` or `y=-1`.\n",
    "    \n",
    "    Tip: use the decision function defined above.\n",
    "    \n",
    "    :param X_pred:  input samples to predict the decision function for\n",
    "    :param a:       lagrange multipliers\n",
    "    :param y_train: target samples from the training set \n",
    "    :param X_train: input samples from the training set\n",
    "    :param b:       bias variable\n",
    "    :param kernel: kernel (function or callable object)\n",
    "    :returns:      prediction yhat={-1, 1} \n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return yhat\n",
    "\n",
    "@contract(y='array[N]',\n",
    "          yhat='array[N]',\n",
    "          returns='number')\n",
    "def accuracy(y, yhat):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy as the number of correctly predicted\n",
    "    target divided by the total number of predictions.\n",
    "        \n",
    "    :param y:    actual target values\n",
    "    :param yhat: predicted target values\n",
    "    :returns:    accuracy score\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f224ee0639025bc8e34815dcac42b9f",
     "grade": true,
     "grade_id": "cell-f9e12abaee390cb4-part-1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = test_data_set\n",
    "f_test = np.asarray([-1.5, -0.8, 0.9, 1.])\n",
    "\n",
    "# Optimize\n",
    "a = optimize_svm(test_data_set.X_train, test_data_set.y_train, linear_kernel)\n",
    "print(\"a:\", a)\n",
    "\n",
    "# Extract support vectors\n",
    "svi = compute_svi(a)\n",
    "print(\"svi:\", svi)\n",
    "\n",
    "support_vectors = test_data_set.X_train[svi]\n",
    "a_sv = a[svi]\n",
    "y_sv = test_data_set.y_train[svi]\n",
    "\n",
    "# Compute b\n",
    "b = compute_b(a_sv, y_sv, support_vectors, linear_kernel)\n",
    "print(\"b:\", b)\n",
    "\n",
    "# Get values decision function\n",
    "\n",
    "## Disable linear_feature function for testing\n",
    "_linear_feature = linear_feature\n",
    "try:\n",
    "    def linear_feature(x):\n",
    "        raise AssertionError(\"Your `compute_b` function uses the `linear_feature` function which is not allowed.\")\n",
    "        \n",
    "    f = decision_function(X_test, a, y_train, X_train, b, linear_kernel)\n",
    "except AssertionError as e:\n",
    "    raise e\n",
    "finally:\n",
    "    linear_feature = _linear_feature\n",
    "    \n",
    "print(\"\\nf:\", f)\n",
    "\n",
    "# Get values prediction\n",
    "y_pred = predict(X_test, a, y_train, X_train, b, linear_kernel)\n",
    "print(\"y:\", y_pred)\n",
    "\n",
    "# Validate accuracy\n",
    "score = accuracy(y_test, y_pred)\n",
    "print(\"score:\", score)\n",
    "\n",
    "assert np.allclose(f, f_test)\n",
    "assert np.allclose(y_pred, y_test)\n",
    "assert abs(score - 1.0) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7e6bb846a44152df26fc89c8bbdf236",
     "grade": false,
     "grade_id": "cell-d9909076f88e45ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3: Should we use `a`, `y` and `X`  or `sv_a`, `sv_y` and `support_vectors`?\n",
    "Lets look at the following functions we have defined in the previous tasks: `compute_w`, `compute_b`, `decision_function` and `predict`. \n",
    "\n",
    "When we computed $b$ it is clear from the theory we have to use the support vectors (`support_vectors`, `sv_a` and `sv_y`). But when we called the other three functions we used the full dataset (`X`, `a` and `y`), wouldn't it be enough to only use the support vectors for these three functions as well? Motivate your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b406952202deac78d3ca3389bb8f8298",
     "grade": true,
     "grade_id": "cell-af898a3b2cd2d281",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2cc3af67f3e5dbf03dec30dddf94f241",
     "grade": false,
     "grade_id": "cell-eaebb4a8d82c7edc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We now have everything we need for our SVM classifier. Let's see what the classifier has learned by updating our figure. Plotting results is useful for interpreting what your model has actually learned, especially during development and implementation of your method. For high dimensional data this becomes difficult of course.\n",
    "\n",
    "In the plots, *dots* indicate training data and *stars* test data. The decision boundary is denoted by a *black line* and the *widest margin* by dotted lines. You don't have to understand how all the functions for generating the plots work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b313cda357353a2b023d728d0cdb64c4",
     "grade": false,
     "grade_id": "cell-e98ea6516ca467ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "X_train, X_test, y_train, y_test = test_data_set\n",
    "\n",
    "# Optimize\n",
    "a = optimize_svm(test_data_set.X_train, test_data_set.y_train, linear_kernel)\n",
    "\n",
    "# Extract support vectors\n",
    "svi = compute_svi(a)\n",
    "\n",
    "support_vectors = test_data_set.X_train[svi]\n",
    "a_sv = a[svi]\n",
    "y_sv = test_data_set.y_train[svi]\n",
    "\n",
    "# Compute w\n",
    "w = compute_w(a, test_data_set.y_train, test_data_set.X_train)\n",
    "\n",
    "# Compute b\n",
    "b = compute_b(a_sv, y_sv, support_vectors, linear_kernel)\n",
    "\n",
    "# Plot data\n",
    "plot_data(ax, test_data_set)\n",
    "\n",
    "# plot support vectors\n",
    "ax.scatter(support_vectors[:, 0], support_vectors[:, 1], s=100,\n",
    "           linewidth=1, facecolors='none', edgecolors='k')\n",
    "\n",
    "# plot the decision function\n",
    "\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "\n",
    "## create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 50)\n",
    "yy = np.linspace(ylim[0], ylim[1], 50)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "margins = decision_function(xy, a_sv, y_sv, support_vectors, b).reshape(XX.shape)\n",
    "Z = np.zeros(margins.shape)\n",
    "Z[margins < 0] = -1\n",
    "Z[margins >= 0] = 1\n",
    "\n",
    "## plot decision boundary and margins   \n",
    "ax.contour(XX, YY, margins, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "ax.contourf(XX, YY, Z, alpha=0.1, colors=[colors[-1], colors[1]])\n",
    "\n",
    "pad_text = -0.2\n",
    "ax.text(0.5, pad_text, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "ax.text(0.5, pad_text-0.075, \"# support vectors: {}\".format(len(svi)), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "ax.text(0.5, pad_text-0.15, \"w: {}\".format(w), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "_ = ax.text(0.5, pad_text-0.225, \"b: {:.2}\".format(b), size=12, ha=\"center\", transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4c3b857ee192be3501542cd594b57d3",
     "grade": false,
     "grade_id": "cell-201ab227ea94e34f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The *black line* is our decision boundary, all samples above the line get $y=1$ (brown) from our predictor and all values below the line $y=-1$ (blue). The *dashed line* indicates the margin of our classifier, i.e., $f(\\mathbf{x}) = 1$, and our support vectors will lay on those lines, the support vectors are *encircled*. The *stars* are our test samples, which have been classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "454ba5a2a6ccc394eeee57335544f148",
     "grade": false,
     "grade_id": "cell-f76a3d5f6f7b309e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Combining All the Parts\n",
    "In order to make working with our classifier more convenient, we have combined all the parts into one class for you. For the rest of the notebook we will be using this class for constructing classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f096b731c33aa8f57bd200c17be7d63c",
     "grade": false,
     "grade_id": "cell-babda36e00e7631c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    \n",
    "    def __init__(self, kernel, threshold=1e-5):\n",
    "        self.kernel = kernel\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        self.svi = None\n",
    "        self.support_vectors = None\n",
    "        self.sv_y = None\n",
    "        self.sv_a = None\n",
    "        self.b = None\n",
    "        \n",
    "    def optmize(self, X, y):\n",
    "        return optimize_svm(X, y, self.kernel)\n",
    "        \n",
    "    def fit(self, X, y):        \n",
    "        # Perform optmization\n",
    "        a = self.optmize(X, y)\n",
    "        if a is None:\n",
    "            return False\n",
    "        \n",
    "        # Determine support vectors (a != 0)\n",
    "        self.svi = compute_svi(a)\n",
    "        \n",
    "        # Store support vector variables we need later\n",
    "        self.support_vectors = X[self.svi]\n",
    "        self.sv_y = y[self.svi]\n",
    "        self.sv_a = a[self.svi]\n",
    "\n",
    "        # Compute b\n",
    "        self.b = compute_b(self.sv_a, self.sv_y, self.support_vectors, kernel=self.kernel)\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    def decision_function(self, x):\n",
    "        if self.b is None:\n",
    "            print(\"Model has not been trained yet, first run '{}.fit(X, y)'\".format(self.__class__.__name__))\n",
    "            return None\n",
    "        \n",
    "        return decision_function(x, self.sv_a, self.sv_y, self.support_vectors, self.b, kernel=self.kernel)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.b is None:\n",
    "            print(\"Model has not been trained yet, first run '{}.fit(X, y)'\".format(self.__class__.__name__))\n",
    "            return None\n",
    "        \n",
    "        return predict(x, self.sv_a, self.sv_y, self.support_vectors, self.b, kernel=self.kernel)\n",
    "    \n",
    "    def score(self, x, y):\n",
    "        if self.b is None:\n",
    "            print(\"Model has not been trained yet, first run '{}.fit(X, y)'\".format(self.__class__.__name__))\n",
    "            return None\n",
    "        \n",
    "        yhat = self.predict(x)\n",
    "        return accuracy_score(y, yhat)\n",
    "    \n",
    "    def plot_decision_boundary(self, ax):\n",
    "        # plot support vectors\n",
    "        ax.scatter(self.support_vectors[:, 0], self.support_vectors[:, 1], s=100,\n",
    "                   linewidth=1, facecolors='none', edgecolors='k')\n",
    "        \n",
    "        # plot the decision function\n",
    "        xlim = ax.get_xlim()\n",
    "        ylim = ax.get_ylim()\n",
    "\n",
    "        ## create grid to evaluate model\n",
    "        xx = np.linspace(xlim[0], xlim[1], 50)\n",
    "        yy = np.linspace(ylim[0], ylim[1], 50)\n",
    "        YY, XX = np.meshgrid(yy, xx)\n",
    "        xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "        \n",
    "        margins = self.decision_function(xy).reshape(XX.shape)\n",
    "        Z = np.zeros(margins.shape)\n",
    "        Z[margins < 0] = -1\n",
    "        Z[margins > 0] = 1\n",
    "         \n",
    "        ## plot decision boundary and margins   \n",
    "        ax.contour(XX, YY, margins, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "                       linestyles=['--', '-', '--'])\n",
    "        ax.contourf(XX, YY, Z, alpha=0.1, colors=[colors[-1], colors[1]])\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d47d141042276a092188c30a8807dbc",
     "grade": false,
     "grade_id": "cell-a46e6abad3b97e3f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Example using SVM Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7f4dc8ee9b0430b9585f3f26e2d1db82",
     "grade": false,
     "grade_id": "cell-217383b718efdd97",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(11,11))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "gs.update(wspace=0.2, hspace=0.5)\n",
    "\n",
    "for i in range(4):\n",
    "    print(\"Solving for data set {}\".format(i))\n",
    "    # Generate random data\n",
    "    X, y = make_blobs(40, centers=2, random_state=i+1)\n",
    "    y[y == 0] = -1\n",
    "    \n",
    "    # Split data into train and test set\n",
    "    data_set = DataSet(*train_test_split(X, y, test_size=0.3))\n",
    "        \n",
    "    # Plot data\n",
    "    ax = plt.subplot(gs[i])\n",
    "    legend = 'upper left' if i == 0 else None\n",
    "    plot_data(ax, data_set, legend)\n",
    "        \n",
    "    # Create SVM with linear kernel\n",
    "    svm = SVM(kernel=linear_kernel)\n",
    "    \n",
    "    # Fit the data\n",
    "    success = svm.fit(data_set.X_train, data_set.y_train)\n",
    "    if not success:\n",
    "        continue\n",
    "        \n",
    "    # For demonstration purpose we compute the weight vector here, but \n",
    "    # remember it is not necessary for solving the svm problem.\n",
    "    w = compute_w(svm.sv_a, svm.sv_y, svm.support_vectors, feature=linear_feature)\n",
    "    \n",
    "    # Validate on test set  \n",
    "    score = svm.score(data_set.X_test, data_set.y_test)\n",
    "        \n",
    "    # Plot margins and predictions\n",
    "    svm.plot_decision_boundary(ax)\n",
    "    \n",
    "    pad_text = -0.2\n",
    "    ax.text(0.5, pad_text, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "    ax.text(0.5, pad_text-0.075, \"# support vectors: {}\".format(len(svm.svi)), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "    ax.text(0.5, pad_text-0.15, \"w: {}\".format(w), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "    ax.text(0.5, pad_text-0.225, \"b: {:.2}\".format(svm.b), size=12, ha=\"center\", transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f37a0e53f63c200fc43f8104c0846a0",
     "grade": false,
     "grade_id": "cell-0995a402f183366e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a href=#Overview> [go to top] </a>\n",
    "# Part 2: Kernels\n",
    "So far we have only looked at data that is linearly separable in the input space $\\mathbf{x}$. But in most data sets that won't be the case, but it might be that the data is linearly separable in some higher dimensional space obtained using a feature mapping $\\phi$. Thanks to the *kernel trick* we don't have to actually transform our data into this high dimensional feature space, but instead only need the associated kernel function.\n",
    "\n",
    "Let's first generate some new data sets, which we will simply call data set `0` and data set `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9e35232826c56f968f0dce0b2762b40",
     "grade": false,
     "grade_id": "cell-0ff6700a06000b2c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n_samples = 200\n",
    "data_sets_kernels = []\n",
    "\n",
    "def add_to_data_sets(X, y):\n",
    "    y[y == 0] = -1\n",
    "    data_set = DataSet(*train_test_split(X, y, test_size=0.3))\n",
    "    data_sets_kernels.append(data_set)\n",
    "\n",
    "X, y = make_circles(n_samples, factor=0.5, noise=0.07)\n",
    "add_to_data_sets(X, y)\n",
    "\n",
    "X, y = make_moons(n_samples, noise=0.1)\n",
    "add_to_data_sets(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "04b659d340e28ba3e2da8c535f70bb8d",
     "grade": false,
     "grade_id": "cell-8ea9934302c06586",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(11,11))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "gs.update(wspace=0.2, hspace=0.5)\n",
    "\n",
    "for i, data_set in enumerate(data_sets_kernels):        \n",
    "    # Plot data\n",
    "    ax = plt.subplot(gs[i])\n",
    "    legend = 'upper right' if i == 1 else None\n",
    "    plot_data(ax, data_set, legend)\n",
    "    ax.text(0.5, -0.2, \"data set: {}\".format(i), size=12, ha=\"center\", transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "054991a24c46570e2313d66a7614735b",
     "grade": false,
     "grade_id": "cell-845e2b04f6d371ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Gaussian Kernel\n",
    "\n",
    "Implement the Gaussian Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9562810c12442c0f079201cfffc1e6cd",
     "grade": false,
     "grade_id": "cell-63139247bf0df8fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class GaussianKernel:\n",
    "    \n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    @contract(x_i='array[M] | array[NxM]',\n",
    "              x_j='array[M] | array[KxM]',\n",
    "              returns='number | array[NxK]')\n",
    "    def __call__(self, x_i, x_j):\n",
    "        \"\"\"\n",
    "        Compute the Gaussian kernel between two vectors.\n",
    "        \n",
    "        The `__call__` method allows us to use instantiated classes as if\n",
    "        they are functions:\n",
    "        \n",
    "          gaussian_kernel = GaussianKernel(0.5)\n",
    "          k = gaussian_kernel(x_i, x_j)\n",
    "          \n",
    "        \n",
    "        :param x_i: first input array\n",
    "        :param x_j: second input array\n",
    "        :returns:   Gaussian kernel \n",
    "        \"\"\"\n",
    "        assert x_i.ndim == x_j.ndim,\\\n",
    "            f\"Kernel only accepts two inputs with the same number of dimensions.\\n\\\n",
    "            \\t x_i.ndim = {x_i.ndim}\\n\\\n",
    "            \\t x_j.ndim = {x_j.ndim}\"\n",
    "        \n",
    "        # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        return k\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1445d0993ea0f808950f7d4e249b096",
     "grade": true,
     "grade_id": "cell-84a3d1c480a43d42-part-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "gaussian_kernel = GaussianKernel(sigma=1.0)\n",
    "\n",
    "assert abs(gaussian_kernel(np.array([1, 2]), np.array([1, 2])) - 1.0) < 1e-3\n",
    "assert abs(gaussian_kernel(np.array([1, 1]), np.array([0, 0])) - 0.368) < 1e-3\n",
    "\n",
    "X_i = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "X_j = np.array([[1, 2, 3], [2, 3, 4]])\n",
    "assert np.allclose(gaussian_kernel(X_i, X_j), np.array([[0.08, 0.], [0.37, 0.08], [0.08, 0.37]]), atol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "199d737bb0c2f4a25aec8d60cfd2865e",
     "grade": false,
     "grade_id": "cell-308994ca81f44ef2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Polynomial Kernel\n",
    "\n",
    "Implement the Polynomial Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf3bfe7fa92416f84d93ca3f563ab776",
     "grade": false,
     "grade_id": "cell-17dbd885db46975b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class PolynomialKernel:\n",
    "    \n",
    "    def __init__(self, c, degree):\n",
    "        self.c = c\n",
    "        self.degree = degree\n",
    "        \n",
    "    @contract(x_i='array[M] | array[NxM]',\n",
    "              x_j='array[M] | array[KxM]',\n",
    "              returns='number |  array[NxK]')        \n",
    "    def __call__(self, x_i, x_j):\n",
    "        \"\"\"\n",
    "        Compute the polynomial kernel between two vectors.\n",
    "        \n",
    "        \n",
    "        :param x_i: first input array\n",
    "        :param x_j: second input array\n",
    "        :returns:   Polynomial kernel \n",
    "        \"\"\"\n",
    "        assert x_i.ndim == x_j.ndim,\\\n",
    "            f\"Kernel only accepts two inputs with the same number of dimensions.\\n\\\n",
    "            \\t x_i.ndim = {x_i.ndim}\\n\\\n",
    "            \\t x_j.ndim = {x_j.ndim}\"\n",
    "        \n",
    "        # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bac3b1503a5015abebce88c45d8873a1",
     "grade": true,
     "grade_id": "cell-1c6426edf5c5d5a3-part-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "polynomial_kernel = PolynomialKernel(c=2.0, degree=3)\n",
    "\n",
    "assert abs(polynomial_kernel(np.array([0, 0]), np.array([1, 0])) - 8.0) < 1e-3\n",
    "assert abs(polynomial_kernel(np.array([1, 2]), np.array([1, 1])) - 125.0) < 1e-3\n",
    "\n",
    "X_i = np.array([[1, 1, 1], [2, 2, 2], [3, 3, 3]])\n",
    "X_j = np.array([[1, 2, 3], [2, 3, 4]])\n",
    "assert np.allclose(polynomial_kernel(X_i, X_j), np.array([[512, 1331], [2744, 8000], [8000, 24389]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73e4c68688cc6df8a450490b97777696",
     "grade": false,
     "grade_id": "cell-77ea7403c773454e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Proof That the Polynomial Kernel is a Valid Kernel\n",
    "During the exercise session of the VO you had to prove that the Gaussian kernel is a valid kernel. Do the same for the polynomial kernel with `degree=2.0` and abitrary `c`. Derive the associated feature mapping $\\phi({\\mathbf{x}})$ and write a function to compute the feature mapping. The function should accept an abitrary size for input vector $\\mathbf{x}$.\n",
    "\n",
    "Tip: first find the solution on a piece of paper when using $\\mathbf{x_i} = [x_1, x_2]$ and $\\mathbf{x_j} = [z_1, z_2]$. And then solve for $\\mathbf{x_i} = [x_1, x_2, x_3]$ and $\\mathbf{x_j} = [z_1, z_2, z_3]$. Look for a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfffb02135a82e91f90ce903377f2b18",
     "grade": false,
     "grade_id": "cell-1b26f5eb921612bb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(x='array[N]',\n",
    "          c='number',\n",
    "          returns='array[K]')\n",
    "def compute_polynomial_feature(x, c):\n",
    "    \"\"\"\n",
    "    Compute second degree polynomial feature.\n",
    "    \n",
    "    :param x: input sample\n",
    "    :param c: constant\n",
    "    :returns: polynomial feature\n",
    "    \"\"\"\n",
    "    degree = 2\n",
    "    \n",
    "    # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aca6002c4e087c96957b6c909d6a1bdc",
     "grade": true,
     "grade_id": "cell-25a67edd8ac11a1a-part-2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "c = 2.0\n",
    "polynomial_kernel = PolynomialKernel(c=c, degree=2)\n",
    "\n",
    "for i in range(3):\n",
    "    x = np.arange(1, i+3)\n",
    "    phi = compute_polynomial_feature(x, c)\n",
    "    print(\"\")\n",
    "    print(\"x_{}:\".format(i), x)\n",
    "    print(\"phi(x_{}):\".format(i), phi)\n",
    "    \n",
    "    assert abs(np.dot(phi, phi) - polynomial_kernel(x, x)) < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c981c6c32a310b0464c1dde85e76f308",
     "grade": false,
     "grade_id": "cell-c06f5eaafdbf737e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Choosing Appropriate Kernels\n",
    "Return the appropriate kernel for each dataset in the function `choose_kernel` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "edabc8777166e7f26bfa86559239a00d",
     "grade": true,
     "grade_id": "cell-530635b9bada75ce",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(data_set_id='int')\n",
    "def choose_kernel(data_set_id):\n",
    "    \"\"\"\n",
    "    Return an appropriate kernel for each data set. Datasets are\n",
    "    shown at the beginning of Part 2.\n",
    "    \n",
    "    Don't forgot to instantiate your kernel before returning and\n",
    "    choose appropriate hyper parameters:\n",
    "    \n",
    "      gaussian_kernel = GaussianKernel(sigma)\n",
    "      return gaussian_kernel\n",
    "    \n",
    "    :param data_set_id: for which data set to return the kernel\n",
    "    \"\"\"\n",
    "    if data_set_id == 0:\n",
    "        \n",
    "        # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    if data_set_id == 1:\n",
    "        \n",
    "        # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "        raise NotImplementedError()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b86ee94268641cca1dbdb62eb5c64dc",
     "grade": false,
     "grade_id": "cell-81db24b1eff4f913",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: Executing this cell may take a few minutes\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(11,11))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "gs.update(wspace=0.2, hspace=0.5)\n",
    "\n",
    "for i, data_set in enumerate(data_sets_kernels):\n",
    "    print(\"solving for dataset {}\".format(i))\n",
    "    \n",
    "    # Plot data\n",
    "    ax = plt.subplot(gs[i])\n",
    "    legend = 'upper right' if i == 1 else None\n",
    "    plot_data(ax, data_set, legend)\n",
    "        \n",
    "    # Create SVM\n",
    "    kernel = choose_kernel(i)\n",
    "    svm = SVM(kernel)\n",
    "    \n",
    "    # Fit the data\n",
    "    success = svm.fit(data_set.X_train, data_set.y_train)\n",
    "    if not success:\n",
    "        continue\n",
    "    \n",
    "    # Validate on test set    \n",
    "    score = svm.score(data_set.X_test, data_set.y_test)\n",
    "        \n",
    "    # Plot Results\n",
    "    svm.plot_decision_boundary(ax)\n",
    "    \n",
    "    pad_text = -0.2\n",
    "    ax.text(0.5, pad_text, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "    ax.text(0.5, pad_text-0.075, \"# support vectors: {}\".format(len(svm.svi)), size=12, ha=\"center\", transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9ceb4dcc971776e3675582bc42f152e",
     "grade": false,
     "grade_id": "cell-d243573f3d0e8884",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a href=#Overview> [go to top] </a>\n",
    "# (Optional) Part 3: $\\nu$-SVM and Multiclass SVM\n",
    "\n",
    "## $\\nu$-SVM\n",
    "So far we have seen data sets that are linearly seperable in some feature space generated by a mapping $\\phi$. In real data this will often not be the case, and the data overlaps or contains some outlier. The standard SVM implementation imposes strict margins, instead we would like to have soft-margins that can deal with this type of data. \n",
    "\n",
    "In other words, for strict margins we want the training data of one class to be strictly on one side of the decision boundary and the other class on the other side and no samples within the margins. For soft margins, we say it is ok if some data samples in our training set are on the wrong side of the boundary or within the margin.\n",
    "\n",
    "One such algorithm is the $\\nu$-SVM. As discussed in the VO, the $\\nu$-SVM problem is defined as follows:\n",
    "\n",
    "$$\\underset{\\mathbf{a}}{\\text{maximize}}\\ \\mathbb{1}_N^T\\mathbf{a} - \\frac{1}{2}\\mathbf{a}^T\\mathbf{P}\\mathbf{a}$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "0 \\leq a_i &\\leq \\frac{1}{N}, \\quad i=1,\\ldots,N \\\\\n",
    "\\mathbf{y}^T \\mathbf{a} &= 0 \\\\\n",
    "\\mathbb{1}_N^T\\mathbf{a} &\\geq \\nu\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c73a6a426a6b99f813340d022e71dd64",
     "grade": false,
     "grade_id": "cell-14ec6862a8dccd45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(231)\n",
    "n_samples = 100\n",
    "data_sets_nu = []\n",
    "\n",
    "for i in range(2):\n",
    "    # Generate random data\n",
    "    X, y = make_blobs(100, centers=2, random_state=i+7, cluster_std=2.7)\n",
    "    y[y == 0] = -1\n",
    "    data_set = DataSet(*train_test_split(X, y, test_size=0.3))\n",
    "    data_sets_nu.append(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8f696e7e60b0586571d2b2bbc692ec0",
     "grade": false,
     "grade_id": "cell-52de73c3b54a11df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(11,11))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "gs.update(wspace=0.2, hspace=0.5)\n",
    "\n",
    "for i, data_set in enumerate(data_sets_nu):\n",
    "    # Plot data\n",
    "    ax = plt.subplot(gs[i])\n",
    "    legend = 'upper left' if i == 0 else None\n",
    "    plot_data(ax, data_set, legend)\n",
    "    ax.text(0.5, -0.2, \"data set: {}\".format(i), size=12, ha=\"center\", transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fcb5e4730d8dc2b989b06ccd5d94c03b",
     "grade": false,
     "grade_id": "cell-b0ba832213ce352e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Update the SVM Optimization to $\\nu$-SVM\n",
    "Write the new constraints for the $\\nu$-SVM in the `optimize_nu_svm` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a568b748645d46813937fcec3dff050",
     "grade": false,
     "grade_id": "cell-d8269cd85766d7f0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@contract(X='array[NxM]',\n",
    "          y='array[N]',\n",
    "          nu='float, >0, <=1',\n",
    "          returns='array[N]')\n",
    "def optimize_nu_svm(X, y, nu, kernel=linear_kernel):\n",
    "    \"\"\"\n",
    "    \n",
    "    :param X:      training values \n",
    "    :param y:      target values \n",
    "    :param nu:     provides bounds on the support vectors, value has to be in interval (0, 1]\n",
    "    :param kernel: kernel\n",
    "    :returns:      Lagrangian multipliers\n",
    "                   None if optimization fails\n",
    "    \"\"\"    \n",
    "    K = kernel(X, X)\n",
    "    P = compute_P(K, y)\n",
    "    P = 0.5 * (P + P.T) # make sure P is symmetric, increases stability of optimization\n",
    "    \n",
    "    N = y.shape[0]\n",
    "    \n",
    "    K = cvxopt.matrix(K)\n",
    "    P = cvxopt.matrix(P)\n",
    "    q = cvxopt.matrix(-1.0 * np.ones(N))\n",
    "    \n",
    "    # Equality constraints\n",
    "    A = cvxopt.matrix(y.astype('float'), (1, N))\n",
    "    b = cvxopt.matrix(0.0)\n",
    "    \n",
    "    # Inequality constraints\n",
    "\n",
    "    # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "    raise NotImplementedError()\n",
    "        \n",
    "    # Solve the problem\n",
    "    solution = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "    \n",
    "    if 'optimal' not in solution['status']:\n",
    "        print(\"No solution could be found, is the data linearly separable in the feature space?\")\n",
    "        return None\n",
    "    \n",
    "    # Lagrangian multipliers\n",
    "    return np.ravel(solution['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9a292fa358bb8147206151996a6f550",
     "grade": false,
     "grade_id": "cell-e82ce523296effd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class NuSVM(SVM):\n",
    "    \"\"\"\n",
    "    We can inherit almost all the functions from our original SVM class.\n",
    "    Only the optmization function has changed.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nu, kernel):\n",
    "        super(NuSVM, self).__init__(kernel)\n",
    "        self.nu = nu\n",
    "        \n",
    "    def optmize(self, X, y):\n",
    "        return optimize_nu_svm(X, y, self.nu, self.kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0fdd8db43014a632d76d972432c9d9d",
     "grade": false,
     "grade_id": "cell-087529439a0d46c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: Executing this cell may take a few minutes\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure(figsize=(11,11))\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "gs.update(wspace=0.2, hspace=0.5)\n",
    "\n",
    "for i, data_set in enumerate(data_sets_nu):\n",
    "    print(\"Solving for data set {}\".format(i))\n",
    "    \n",
    "    # Plot data\n",
    "    ax = plt.subplot(gs[i])\n",
    "    legend = 'upper left' if i == 0 else None\n",
    "    plot_data(ax, data_set, legend)\n",
    "        \n",
    "    # Create SVM with linear kernel\n",
    "    svm = NuSVM(nu=1.0, kernel=linear_kernel)\n",
    "    \n",
    "    # Fit the data\n",
    "    success = svm.fit(data_set.X_train, data_set.y_train)\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    w = compute_w(svm.sv_a, svm.sv_y, svm.support_vectors, feature=linear_feature)\n",
    "    \n",
    "    # Validate on test set  \n",
    "    score = svm.score(data_set.X_test, data_set.y_test)\n",
    "    \n",
    "    # Plot margins and predictions\n",
    "    svm.plot_decision_boundary(ax)\n",
    "    \n",
    "    pad_text = -0.2\n",
    "    ax.text(0.5, pad_text, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "    ax.text(0.5, pad_text-0.075, \"# support vectors: {}\".format(len(svm.svi)), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "    ax.text(0.5, pad_text-0.15, \"w: {}\".format(w), size=12, ha=\"center\", transform=ax.transAxes)\n",
    "    ax.text(0.5, pad_text-0.225, \"b: {:.2}\".format(svm.b), size=12, ha=\"center\", transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca7ba0ac42d3e4b093fc74171cc0abba",
     "grade": false,
     "grade_id": "cell-4cea34314d0bc114",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a href=#objectives> [go to top] </a>\n",
    "## Multiclass SVM\n",
    "In the last part of this notebook we will be implementing a simple implementation to solve the multiclass SVM problem and evaluate on the iris data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "893b70e96baecabc636ef1cd25399ce1",
     "grade": false,
     "grade_id": "cell-4c0eba042923f314",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data_set = load_iris()\n",
    "y = iris_data_set['target']\n",
    "\n",
    "# Select the 'sepal length' and 'petal length' columns from the dataset\n",
    "used_features = ['sepal length (cm)', 'petal length (cm)']\n",
    "data_col = list()\n",
    "for col, val in enumerate(iris_data_set['feature_names']):\n",
    "    if(val in used_features):\n",
    "        data_col.append(col)\n",
    "\n",
    "X = iris_data_set['data'][:,data_col]\n",
    "data_set_iris = DataSet(*train_test_split(X, y, test_size=0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be9d0327abdc107a89ed1d3f51559e92",
     "grade": false,
     "grade_id": "cell-00e06fb4ab19249d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_iris_dataset(ax, data_set_iris, x_label = 'sepal length (cm)', y_label = 'sepal width (cm)'):\n",
    "    X_train, X_test, y_train, y_test = data_set_iris\n",
    "    \n",
    "    # Scatter plotting the data, filtering them according the pos/neg values\n",
    "    for i, label in enumerate(['setosa', 'versicolour', 'virginica']):\n",
    "        idx_train = y_train == i\n",
    "        idx_test = y_test == i\n",
    "\n",
    "        ax.scatter(X_train[idx_train, 0], X_train[idx_train, 1], s=30, c=[colors[i]], label='{} (train)'.format(label))\n",
    "        ax.scatter(X_test[idx_test, 0], X_test[idx_test, 1], c=[colors[i]], s=50, marker='x', label='{} (test)'.format(label))\n",
    "\n",
    "    # Labels and limits\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xlim(X[:, 0].min()-0.1, X[:, 0].max()+0.1)\n",
    "    ax.set_ylim(X[:, 1].min()-0.1, X[:, 1].max()+0.1)\n",
    "\n",
    "    # Legend\n",
    "    pst = ax.legend(loc='lower right', frameon=True)\n",
    "    pst.get_frame().set_edgecolor('k')\n",
    "    \n",
    "\n",
    "def plot_decision_boundary(ax, predict_function):        \n",
    "    # plot the decision function\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    # create grid to evaluate model\n",
    "    xx = np.linspace(xlim[0], xlim[1], 100)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 100)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "\n",
    "    Z = predict_function(xy).reshape(XX.shape)\n",
    "\n",
    "    # plot decision boundary \n",
    "    ax.contourf(XX, YY, Z, levels=2, colors=colors, alpha=0.1)\n",
    "    ax.contour(XX, YY, Z, levels=2, colors=colors, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cff747a791a17c53ea7d188111354267",
     "grade": false,
     "grade_id": "cell-48a2b6e34978acd6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "ax = plt.gca()\n",
    "plot_iris_dataset(ax, data_set_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb564fc6f32bb3a776691f7d635cae8a",
     "grade": false,
     "grade_id": "cell-a32e2232f74f4feb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement Multiclass SVM\n",
    "One method for solving the multiclass SVM problem is the \"one versus the rest\" approach as explained in the lecture:\n",
    "\n",
    "1. Construct $M$ separate SVMs.\n",
    "2. The $m$-th model $f_m(\\mathbf{x})$ is trained using data from class $C_m$ as positive examples ($y_m = +1$) and the data from the remaining $M - 1$ classes as negative samples $y_{i \\neq m} = -1$.\n",
    "3. Train each model separately.\n",
    "\n",
    "For prediction return the class label associated with the model $m$ that returns a positive prediction ($+1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "89a2b5123c49c69de95a1033f6f53115",
     "grade": false,
     "grade_id": "cell-fc962353077ccca1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class MulticlassSVM:\n",
    "    \n",
    "    def __init__(self, nu, kernel):\n",
    "        self.nu = nu\n",
    "        self.kernel = kernel\n",
    "        \n",
    "    @contract(X='array[NxM]',\n",
    "              y='array[N]',\n",
    "              returns='bool')\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Implement the training procedure for the Multiclass SVM.\n",
    "        \n",
    "        :param X: training values\n",
    "        :param y: target values\n",
    "        :returns: True if successful, False otherwise\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    @contract(x='array[M] | array[NxM]',\n",
    "              returns='int | array[N]')\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Implement the predictor for the Multiclass SVM.\n",
    "        \n",
    "        :param x: input sample\n",
    "        :returns: predicted class\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        return yhat\n",
    "        \n",
    "    def score(self, x, y):\n",
    "        yhat = self.predict(x)\n",
    "        return accuracy_score(y, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b92f91048f6db840d1ce6716149c6f4",
     "grade": false,
     "grade_id": "cell-7740f8a5ef6a6dbe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def return_multiclass_svm_iris(data_set_iris):\n",
    "    \"\"\"\n",
    "    Create a Multiclass SVM trained on the iris data set.\n",
    "    \n",
    "    Choose appropriate hyperpameter values and kernels. Play \n",
    "    around and find some solution that solves the problem\n",
    "    \n",
    "    :param data_set_iris: the iris data set variable\n",
    "    :returns:             trained MulticlassSVM\n",
    "    \"\"\"\n",
    "    X_train, _, y_train, _ = data_set_iris\n",
    "    \n",
    "    # YOUR CODE HERE (please remove 'raise NotImplementedError()')\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    return svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bbca3f36b95eb973f986f57f861b992",
     "grade": false,
     "grade_id": "cell-8675d10ae3cb69b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: Executing this cell may take a few minutes\n",
    "\n",
    "multiclass_svm = return_multiclass_svm_iris(data_set_iris)\n",
    "score = multiclass_svm.score(data_set_iris.X_test, data_set_iris.y_test)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "ax = plt.gca()\n",
    "plot_iris_dataset(ax, data_set_iris)\n",
    "plot_decision_boundary(ax, multiclass_svm.predict)\n",
    "_ = ax.text(0.5, -0.2, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43867a4b859bd88e8be513bf7f5194b8",
     "grade": false,
     "grade_id": "cell-aa6a452a011e458f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 4: What is a Limitation of the \"One Versus All\" approach?\n",
    "And can you come up with a modification to overcome this limitation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0e7775cf6a59415db7bdc1df982ae119",
     "grade": true,
     "grade_id": "cell-cc6a009bbc00ee4c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff4e179721b010feb8808ff4b5cffaa3",
     "grade": false,
     "grade_id": "cell-2c338a5ab880f347",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<a href=#Overview> [go to top] </a>\n",
    "# (Optional) Part 4: Scikit-Learn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c39aada94ce3aa9c83f6529ebd586d04",
     "grade": false,
     "grade_id": "cell-5fff3d9667b3108f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "# Scikit learn has a different default SVM implementation called C-Support Vector Classification\n",
    "sk_svm = SVC(C=100000, kernel='poly', degree=2) \n",
    "\n",
    "sk_svm.fit(data_set_iris.X_train, data_set_iris.y_train)\n",
    "score = sk_svm.score(data_set_iris.X_test, data_set_iris.y_test)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "ax = plt.gca()\n",
    "plot_iris_dataset(ax, data_set_iris)\n",
    "plot_decision_boundary(ax, sk_svm.predict)\n",
    "_ = ax.text(0.5, -0.2, \"accuracy: {:.2}\".format(score), size=12, ha=\"center\", transform=ax.transAxes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "167px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "480.85px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
